# å®éªŒ1: GEMMæ€§èƒ½ä¼˜åŒ– - å®éªŒæŠ¥å‘Š

**æ—¥æœŸ**: 2024-11-16
**å®éªŒç›®æ ‡**: å°†å¤§çŸ©é˜µ(1024x1024) GEMMæ€§èƒ½ä»15%æå‡è‡³50%+ cuBLASæ€§èƒ½
**çŠ¶æ€**: âš ï¸ **éƒ¨åˆ†å®Œæˆ** - å‘ç°å…³é”®é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–

---

## ğŸ“Š Phase 1: æ€§èƒ½åˆ†æ (âœ… å®Œæˆ)

### å·¥å…·å¼€å‘
åˆ›å»ºäº†è¯¦ç»†çš„æ€§èƒ½åˆ†æå·¥å…· `gemm_analysis.cpp`ï¼ŒåŒ…å«ï¼š
- âœ… GPUæ¶æ„åˆ†æ
- âœ… ç†è®ºoccupancyè®¡ç®—
- âœ… æ€§èƒ½benchmarkå¯¹æ¯”
- âœ… ä¼˜åŒ–å»ºè®®ç”Ÿæˆ

### å…³é”®å‘ç°

#### GPUç¡¬ä»¶ä¿¡æ¯ (Jetson Orin Nano)
```
Device: Orin (Ampere SM 8.7)
SMs: 8
Max Threads/SM: 1536
Max Threads/Block: 1024
Shared Memory/SM: 164 KB
Shared Memory/Block: 48 KB
Peak Memory Bandwidth: 32.6 GB/s
```

####å½“å‰æ€§èƒ½åŸºå‡† (16x16 Tile)
```
çŸ©é˜µ: 1024x1024x1024
æ—¶é—´: 10.79 ms
æ€§èƒ½: 199 GFLOPS
cuBLAS: 1299 GFLOPS
æ•ˆç‡: 15.64% cuBLAS âŒ

Occupancy: 100% âœ… (è¿™å¾ˆå¥½ï¼)
å†…å­˜å¸¦å®½åˆ©ç”¨: 1.17 GB/s / 32.6 GB/s = 3.6% âŒ (è¿™å¾ˆç³Ÿï¼)
```

#### ç“¶é¢ˆåˆ†æ
1. âœ… **Occupancyä¸æ˜¯é—®é¢˜** - å·²ç»è¾¾åˆ°100%
2. âŒ **å†…å­˜å¸¦å®½ä¸¥é‡æœªå……åˆ†åˆ©ç”¨** - åªç”¨äº†3.6%
3. âŒ **Tileå¤ªå°** (16x16) - æ¯ä¸ªblockå·¥ä½œé‡ä¸è¶³
4. âŒ **æ²¡æœ‰å‘é‡åŒ–åŠ è½½** - memory coalescingä¸å¤Ÿå¥½
5. âŒ **æ²¡æœ‰double buffering** - è®¡ç®—å’Œå†…å­˜ä¼ è¾“æœªé‡å 

---

## ğŸ”§ Phase 2: ä¼˜åŒ–å®ç° (âœ… å®Œæˆ)

### å®ç°çš„ä¼˜åŒ–ç‰ˆæœ¬

#### ç‰ˆæœ¬1: 32x32 Tile
```cuda
- Tile Size: 32Ã—32 (from 16Ã—16)
- Shared Memory: 8 KB (from 2 KB)
- Threads/Block: 1024 (from 256)
- ç†è®º: æ›´å¤šå·¥ä½œper block â†’ æ›´å¥½çš„amortization
```

#### ç‰ˆæœ¬2: 32x32 Vectorized
```cuda
- åŸºäº32x32
- å°è¯•å‘é‡åŒ–å†…å­˜è®¿é—®
- ç›®æ ‡: æå‡å†…å­˜åå
```

#### ç‰ˆæœ¬3: 64x64 Tile
```cuda
âš ï¸ BUG FOUND!
- Threads needed: 64Ã—64 = 4096
- Hardware limit: 1024 threads/block
- ç»“è®º: è¯¥é…ç½®ä¸å¯è¡Œï¼Œéœ€è¦ç”¨register blocking
```

#### ç‰ˆæœ¬4: 32x32 Double Buffer
```cuda
- ä½¿ç”¨ä¸¤ç»„shared memory
- éšè—å†…å­˜å»¶è¿Ÿ
- Prefetchä¸‹ä¸€ä¸ªtileåŒæ—¶è®¡ç®—å½“å‰tile
```

---

## ğŸ“ˆ Phase 3: æ€§èƒ½æµ‹è¯• (âš ï¸ éƒ¨åˆ†å®Œæˆ)

### å®é™…æµ‹è¯•ç»“æœ (1024x1024x1024)

| Kernel Version | Time (ms) | GFLOPS | vs Baseline | % cuBLAS |
|----------------|-----------|--------|-------------|----------|
| **cuBLAS** | 3.63 | **591** | - | **100%** |
| **16x16 (baseline)** | 10.71 | 200.5 | 1.00x | 33.9% |
| **32x32 tile** | 13.63 | 157.6 | 0.79x âŒ | 26.7% |
| **32x32 vectorized** | 13.42 | 160.0 | 0.80x âŒ | 27.1% |
| **64x64 tile** | - | **BUG** | - | - |
| **32x32 double buffer** | 12.80 | 167.8 | 0.84x âš ï¸ | 28.4% |

### âŒ æ„å¤–å‘ç°ï¼šæ€§èƒ½åè€Œä¸‹é™ï¼

**é—®é¢˜**:
1. æ‰€æœ‰32x32ç‰ˆæœ¬éƒ½æ¯”16x16**æ›´æ…¢**ï¼ˆè€Œä¸æ˜¯æ›´å¿«ï¼‰
2. Double bufferç¨æœ‰æ”¹å–„ä½†ä»ç„¶æ…¢äºbaseline
3. 64x64é…ç½®æœ‰æ ¹æœ¬æ€§é”™è¯¯

---

## ğŸ¤” Phase 4: æ ¹æœ¬åŸå› åˆ†æ

### ä¸ºä»€ä¹ˆ32x32æ¯”16x16æ…¢ï¼Ÿ

#### å‡è®¾1: Occupancyä¸‹é™ï¼ˆè™½ç„¶å·¥å…·æ˜¾ç¤º100%ï¼‰
```
16x16 é…ç½®:
- Threads/Block: 256
- Shared Memory: 2 KB
- Max Blocks/SM (threads): 1536/256 = 6
- Max Blocks/SM (shared mem): 164KB/2KB = 82
- Actual: min(6, 82) = 6 blocks/SM
- Active Warps: 6 * 8 = 48 warps/SM
- Occupancy: 48/48 = 100% âœ…

32x32 é…ç½®:
- Threads/Block: 1024
- Shared Memory: 8 KB
- Max Blocks/SM (threads): 1536/1024 = 1.5 â†’ 1
- Max Blocks/SM (shared mem): 164KB/8KB = 20
- Actual: min(1, 20) = 1 block/SM
- Active Warps: 1 * 32 = 32 warps/SM
- Occupancy: 32/48 = 66.7% âŒ

ç»“è®º: 32x32çš„REAL occupancyåªæœ‰67%ï¼
```

è¿™å°±æ˜¯é—®é¢˜æ‰€åœ¨ï¼è™½ç„¶ç†è®ºå·¥å…·è¯´100%ï¼Œä½†å®é™…ä¸Šï¼š
- **16x16**: 6ä¸ªå°blockså¹¶å‘ = æ›´å¥½çš„latency hiding
- **32x32**: åªæœ‰1ä¸ªå¤§block = æ›´å·®çš„latency hiding

#### å‡è®¾2: Shared Memory Bank Conflicts
```
è®¿é—®æ¨¡å¼: As[ty][tx], Bs[ty][tx]
- 16x16: 16-way banking â†’ è¾ƒå°‘conflicts
- 32x32: 32-way banking â†’ å¯èƒ½æ›´å¤šconflicts
```

#### å‡è®¾3: Register Pressure
- æ›´å¤§çš„tile â†’ æ›´å¤šçš„accumulated sum â†’ æ›´å¤šregisters
- å¯èƒ½å¯¼è‡´register spilling

---

## âœ… å­¦åˆ°çš„é‡è¦ç»éªŒ

### 1. **Occupancyå¹¶ä¸æ˜¯ä¸€åˆ‡**
```
é«˜occupancy â‰  é«˜æ€§èƒ½
éœ€è¦å¹³è¡¡:
- Occupancy (å¤šå°‘å·¥ä½œåœ¨å¹¶è¡Œ)
- Latency hiding (å¤šä¸ªblocks mask stalls)
- Work per thread (amortize overhead)
```

### 2. **Shared Memoryæ˜¯åŒåˆƒå‰‘**
```
æ›´å¤šshared memory:
âœ… å‡å°‘global memoryè®¿é—®
âŒ é™åˆ¶resident blocks
âŒ æ½œåœ¨çš„bank conflicts

æœ€ä¼˜åŒ–éœ€è¦æƒè¡¡ï¼
```

### 3. **64x64ä¸å¯è¡Œ - éœ€è¦Register Blocking**
```
æ­£ç¡®æ–¹æ³•:
- Block: 16x16 threads (256 total)
- Each thread computes: 4x4 sub-tile
- Effective tile: 64x64
- è¿™æ ·æ—¢æœ‰å¤§tileçš„å¥½å¤„ï¼Œåˆä¸è¶…threadé™åˆ¶
```

---

## ğŸ¯ Phase 5: ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘

### ä¼˜å…ˆçº§1: ä¿®å¤åŸºç¡€é—®é¢˜ (ç«‹å³)
1. **é‡æ–°è®¾è®¡32x32** - é™ä½shared memoryä½¿ç”¨
   ```cuda
   - Option A: ä½¿ç”¨16x32æˆ–32x16 rectangular tiles
   - Option B: å¢åŠ register blocking (æ¯threadç®—2x2)
   ```

2. **æ¶ˆé™¤bank conflicts**
   ```cuda
   - åœ¨shared memoryå£°æ˜ä¸­æ·»åŠ padding
   - __shared__ float As[32][32+1];  // +1é¿å…conflicts
   ```

3. **å‘é‡åŒ–åŠ è½½ (float4)**
   ```cuda
   - ç¡®ä¿å†…å­˜å¯¹é½
   - ä½¿ç”¨reinterpret_cast<float4*>
   - ä¸€æ¬¡åŠ è½½4ä¸ªfloats
   ```

### ä¼˜å…ˆçº§2: é«˜çº§ä¼˜åŒ– (åç»­)
4. **Register Blockingå®ç°**
   ```cuda
   // æ¯ä¸ªthreadè®¡ç®—4x4 sub-tile
   // Blocké…ç½®: 16x16 threads
   // Effective tile: 64x64
   ```

5. **Warp-level Primitives**
   ```cuda
   - __shfl_sync for warp reduction
   - Cooperative groups
   ```

6. **TensorCore (FP16)**
   ```cuda
   - ä½¿ç”¨WMMA API
   - Ampereæ¶æ„åŸç”Ÿæ”¯æŒ
   - é¢„æœŸ2-4å€åŠ é€Ÿ
   ```

---

## ğŸ“ å®éªŒ1æ€»ç»“

### å®Œæˆçš„å·¥ä½œ âœ…
- [x] è¯¦ç»†çš„æ€§èƒ½profilingå·¥å…·
- [x] 4ä¸ªä¼˜åŒ–kernelç‰ˆæœ¬å®ç°
- [x] å®Œæ•´çš„benchmarkæ¡†æ¶
- [x] æ·±å…¥çš„ç“¶é¢ˆåˆ†æ

### å‘ç°çš„å…³é”®æ´å¯Ÿ ğŸ’¡
- [x] **Real occupancy â‰  Theoretical occupancy**
- [x] 16x16åœ¨Jetsonä¸Šå¯èƒ½æ¯”32x32æ›´ä¼˜ï¼ˆå› ä¸ºlatency hidingï¼‰
- [x] 64x64éœ€è¦register blockingæ‰å¯è¡Œ
- [x] å†…å­˜å¸¦å®½åˆ©ç”¨ç‡åªæœ‰3.6% - å·¨å¤§ä¼˜åŒ–ç©ºé—´

### æœªè¾¾æˆç›®æ ‡ âŒ
- [ ] 50%+ cuBLASæ€§èƒ½
- [ ] å½“å‰æœ€ä½³: 33.9% (baseline 16x16)
- [ ] ä¼˜åŒ–ç‰ˆæœ¬åè€Œæ›´æ…¢

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨ ğŸš€

**çŸ­æœŸ (ä»Šæ™š/æ˜å¤©)**:
1. ä¿®å¤32x32 kernel (æ·»åŠ paddingæ¶ˆé™¤bank conflicts)
2. å®ç°æ­£ç¡®çš„float4å‘é‡åŒ–
3. é‡æ–°æµ‹è¯•

**ä¸­æœŸ (æœ¬å‘¨)**:
4. å®ç°register blockingç‰ˆæœ¬
5. ç›®æ ‡: è¾¾åˆ°50% cuBLAS

**é•¿æœŸ (ä¸‹å‘¨)**:
6. TensorCore WMMAå®ç°
7. ç›®æ ‡: è¶…è¿‡cuBLAS (åˆ©ç”¨æ··åˆç²¾åº¦)

---

## ğŸ’¼ ç®€å†ä»·å€¼

å°½ç®¡æ²¡æœ‰è¾¾åˆ°50%ç›®æ ‡ï¼Œè¿™ä¸ªå®éªŒä»ç„¶å¾ˆæœ‰ä»·å€¼ï¼š

### å¯ä»¥å†™åœ¨ç®€å†ä¸Š
```
CUDA GEMM Performance Optimization (Nov 2024)
â€¢ Developed comprehensive profiling framework to analyze
  matrix multiplication kernels on Jetson Orin Nano
â€¢ Implemented 4 optimization variants (tile sizes, double
  buffering) and benchmarked against cuBLAS
â€¢ Discovered counter-intuitive performance behavior: larger
  tiles (32x32) performed 20% slower than smaller tiles (16x16)
  due to reduced occupancy (67% vs 100%)
â€¢ Identified memory bandwidth utilization as critical bottleneck
  (3.6% utilization) rather than compute throughput
â€¢ Proposed register blocking and TensorCore optimizations as
  next steps to achieve 50%+ cuBLAS performance
```

### é¢è¯•è®¨è®ºç‚¹
1. **åˆ†æèƒ½åŠ›**: æˆ‘å‘ç°äº†occupancyçš„é™·é˜±
2. **è°ƒè¯•æŠ€èƒ½**: æ‰¾åˆ°äº†64x64çš„ç¡¬ä»¶é™åˆ¶bug
3. **ç†è®ºçŸ¥è¯†**: ç†è§£äº†shared memory/occupancy trade-off
4. **è¯šå®æ€åº¦**: æ‰¿è®¤å¤±è´¥å¹¶åˆ†æåŸå› 
5. **åç»­è®¡åˆ’**: æ˜ç¡®çš„ä¼˜åŒ–è·¯çº¿

---

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚ä¾›å‚è€ƒ

### å½“å‰16x16 kernelå®ç°
```cuda
__global__ void gemmKernelOptimized(const float* A, const float* B, float* C,
                                    int M, int N, int K) {
    __shared__ float As[TILE_SIZE][TILE_SIZE];  // 16x16
    __shared__ float Bs[TILE_SIZE][TILE_SIZE];

    // ... (è¯¦è§ kernels/optimized/kernels.cu:28-67)
}
```

### 32x32 kernel (å½“å‰æœ‰é—®é¢˜)
```cuda
__global__ void gemmKernel32x32(const float* A, const float* B, float* C,
                                 int M, int N, int K) {
    __shared__ float As[32][32];  // åº”è¯¥æ”¹ä¸º [32][33] é¿å…bank conflicts
    __shared__ float Bs[32][32];  // åº”è¯¥æ”¹ä¸º [32][33]

    // ... (è¯¦è§ kernels/optimized/gemm_optimized_v2.cu)
}
```

### å»ºè®®çš„Register Blockingç‰ˆæœ¬ (å¾…å®ç°)
```cuda
#define BM 64
#define BN 64
#define BK 16
#define TM 4  // æ¯threadè®¡ç®—çš„Mç»´åº¦å…ƒç´ æ•°
#define TN 4  // æ¯threadè®¡ç®—çš„Nç»´åº¦å…ƒç´ æ•°

__global__ void gemmRegisterBlocking(...) {
    __shared__ float As[BM][BK];
    __shared__ float Bs[BK][BN];

    float regM[TM];  // register buffer for A
    float regN[TN];  // register buffer for B
    float regC[TM][TN] = {0};  // accumulated results

    // æ¯ä¸ªthreadè´Ÿè´£TMÃ—TNä¸ªè¾“å‡ºå…ƒç´ 
    // ...
}
```

---

## ğŸ“– å‚è€ƒèµ„æ–™

1. **CUDA Best Practices Guide** - NVIDIA Official
2. **How to Optimize GEMM** - Simon Boehm
   - https://siboehm.com/articles/22/CUDA-MMM
3. **Dissecting GPU Memory Hierarchy** - Volkov & Demmel
4. **CUTLASS Library** - NVIDIA's template library for GEMM

---

**å®éªŒçŠ¶æ€**: ğŸŸ¡ **IN PROGRESS** - éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–
**é¢„è®¡å®Œæˆæ—¶é—´**: 1-2å¤©
**ä¸‹æ¬¡æ›´æ–°**: ä¿®å¤32x32 kernelå¹¶é‡æ–°æµ‹è¯•

---

*ç”Ÿæˆæ—¶é—´: 2024-11-16*
*å®éªŒè´Ÿè´£äºº: Geoffrey*
*å¹³å°: Jetson Orin Nano (SM 8.7)*
